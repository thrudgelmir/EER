{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5fb95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, warnings, sys, time\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from config import cols, labels\n",
    "from train_functions.MLPLogisticFL import MLPLogisticFL\n",
    "from train_functions.fncs import select_feature\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "seed = 0\n",
    "type = 'Wesad'\n",
    "df = pd.read_csv(f'./datas/{type}.csv',index_col=0)\n",
    "print(df.shape)\n",
    "logo = LeaveOneGroupOut()\n",
    "groups = df['pnum']\n",
    "unique_groups = np.unique(groups)\n",
    "group_count = len(unique_groups)\n",
    "print(group_count)\n",
    "\n",
    "personal = 100\n",
    "hidden = 32\n",
    "epochs = 1\n",
    "lr = 1e-3\n",
    "rounds = 100\n",
    "L = 0.1\n",
    "participation_ratio = 0.8\n",
    "import math\n",
    "\n",
    "def compute_tau(C, Cs, R, tau_min=0.5, tau_max=0.9, delta=0.5):\n",
    "    progress = (C - delta * (C - Cs)) / R\n",
    "    progress = min(max(progress, 0), 1)  # clamp to [0,1]\n",
    "    cosine = math.cos(math.pi * progress)\n",
    "    tau = tau_max - 0.5 * (tau_max - tau_min) * (1 + cosine)\n",
    "    return tau\n",
    "\n",
    "def fl_run() :\n",
    "    accs = []\n",
    "    for i, (train_idx, test_idx) in enumerate(logo.split(df, df[labels[type]], groups)):\n",
    "        \n",
    "        x_data = df.drop(columns=cols[type])\n",
    "        y_data = df[labels[type]]\n",
    "        x_train, x_test = np.array(x_data.iloc[train_idx]), np.array(x_data.iloc[test_idx])\n",
    "        y_train, y_test = np.array(y_data.iloc[train_idx]).reshape(-1,1), np.array(y_data.iloc[test_idx]).reshape(-1,1)\n",
    "        pnum_train = groups.iloc[train_idx].values\n",
    "        pnum_test = groups.iloc[test_idx].values\n",
    "        # test 개인의 일부 제거\n",
    "        x_test, y_test = x_test[personal:], y_test[personal:]\n",
    "\n",
    "        # FedAvg를 위한 클라이언트 분할\n",
    "        client_ids = np.unique(pnum_train)\n",
    "        client_models = {cid:MLPLogisticFL(x_train.shape[1], hidden, epochs, lr) for cid in client_ids}\n",
    "        client_participation = {cid: 0 for cid in client_ids}\n",
    "        client_data_sizes = {cid: (pnum_train == cid).sum() for cid in client_ids}\n",
    "        total_data_size = sum(client_data_sizes.values())\n",
    "        client_weights = {cid: client_data_sizes[cid] / total_data_size for cid in client_ids}\n",
    "\n",
    "        client_params = {}\n",
    "        \n",
    "        # 로컬 학습\n",
    "        global_model = MLPLogisticFL(x_train.shape[1], hidden, epochs, lr)\n",
    "        torch.save(global_model.state_dict(),'save.pt')\n",
    "        accs.append([])\n",
    "        for round in range(rounds) :\n",
    "            num_clients = len(client_ids)\n",
    "            selected_clients = np.random.choice(\n",
    "                client_ids, size=int(num_clients * participation_ratio), replace=False\n",
    "            )\n",
    "\n",
    "            for cid in selected_clients:\n",
    "                bef = client_models[cid].t\n",
    "                client_models[cid].t = compute_tau(round,client_participation[cid],rounds)\n",
    "                client_participation[cid] += 1\n",
    "                idx = np.where(pnum_train == cid)[0]\n",
    "                x_local, y_local = x_train[idx], y_train[idx]\n",
    "                k = int(len(x_local)*L)\n",
    "                x_local2 = x_local[k:]\n",
    "                x_local,y_local = x_local[:k],y_local[:k]\n",
    "                client_models[cid].load_state_dict(torch.load('save.pt'))\n",
    "                client_models[cid].fit(x_local,x_local2, y_local)\n",
    "                client_params[cid] = {k: v.detach().clone() for k, v in client_models[cid].state_dict().items()}\n",
    "            \n",
    "            # FedAvg: 파라미터 평균\n",
    "            global_params = defaultdict(lambda: 0)\n",
    "            for k in client_params[selected_clients[0]]:\n",
    "                for cid in selected_clients:\n",
    "                    global_params[k] += client_params[cid][k] * client_weights[cid]\n",
    "            \n",
    "            # 글로벌 모델 생성 및 파라미터 반영\n",
    "            \n",
    "            global_model.load_state_dict(global_params)\n",
    "            torch.save(global_model.state_dict(),'save.pt')\n",
    "\n",
    "            logits = global_model.forward(torch.Tensor(x_test))\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            pred = torch.argmax(probs, dim=1).numpy()\n",
    "            accs[-1].append(accuracy_score(y_test, pred))\n",
    "        \n",
    "        #f1s.append(f1_score(y_test, pred))\n",
    "\n",
    "        bar = '[' + '=' * int((i + 1) * 31 / group_count) + ' ' * (31 - int((i + 1) * 31 / group_count)) + ']'\n",
    "        percent = ((i + 1) / group_count) * 100\n",
    "        sys.stdout.write(f'\\rProgress: {bar} {percent:.2f}% ({(i + 1)}/{group_count})')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c649183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = []\n",
    "for i in range(5) :\n",
    "    rets.append(fl_run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef6a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in np.mean(rets,axis=0) :\n",
    "    plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for times in rets :\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.mean(np.mean(rets,axis=0),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c2bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_times = np.mean(np.mean(rets,axis=1),axis=-1)\n",
    "print(f'{np.mean(acc_times):.4f} {np.std(acc_times):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41aea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(np.mean(rets,axis=-2),axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
